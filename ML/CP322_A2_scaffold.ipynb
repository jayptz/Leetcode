{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6393be37",
   "metadata": {},
   "source": [
    "\n",
    "# CP322 — Assignment 2: Fake vs Real News Classification\n",
    "\n",
    "**Dataset:** Fake and Real News — Kaggle  \n",
    "**Goal:** Build classifiers (Naive Bayes, Logistic Regression, MLP) to detect fake news from text.  \n",
    "**Student:** Jay Patel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb98f5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python3.11\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6750bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0793a454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3709f15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp311-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.9 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torchvision) (11.3.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.0-cp311-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.0-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.9.0-cp311-cp311-macosx_11_0_arm64.whl (808 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.4/808.4 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━\u001b[0m \u001b[32m0/9\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.9.09\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.9.0:━━━\u001b[0m \u001b[32m0/9\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.9.0━━━━━━━━━━━━\u001b[0m \u001b[32m1/9\u001b[0m [typing-extensions]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [torchaudio]9\u001b[0m [torchaudio]]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.20.0 fsspec-2025.9.0 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.9.0 torchaudio-2.9.0 torchvision-0.24.0 typing-extensions-4.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b8aed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55d8b15",
   "metadata": {},
   "source": [
    "## 0) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20243f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1006)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1006)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1006)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os, re, math, random, string, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, roc_curve, confusion_matrix)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ca7ec9",
   "metadata": {},
   "source": [
    "## 1) Data Exploration & Preprocessing (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6bf44",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Load & Merge\n",
    "Load `True.csv` (label=0) and `Fake.csv` (label=1). Keep `title` and `text` only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65905954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BREAKING: GOP Chairman Grassley Has Had Enoug...</td>\n",
       "      <td>Donald Trump s White House is in chaos, and th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Failed GOP Candidates Remembered In Hilarious...</td>\n",
       "      <td>Now that Donald Trump is the presumptive GOP n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike Pence’s New DC Neighbors Are HILARIOUSLY...</td>\n",
       "      <td>Mike Pence is a huge homophobe. He supports ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California AG pledges to defend birth control ...</td>\n",
       "      <td>SAN FRANCISCO (Reuters) - California Attorney ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZ RANCHERS Living On US-Mexico Border Destroy...</td>\n",
       "      <td>Twisted reasoning is all that comes from Pelos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   BREAKING: GOP Chairman Grassley Has Had Enoug...   \n",
       "1   Failed GOP Candidates Remembered In Hilarious...   \n",
       "2   Mike Pence’s New DC Neighbors Are HILARIOUSLY...   \n",
       "3  California AG pledges to defend birth control ...   \n",
       "4  AZ RANCHERS Living On US-Mexico Border Destroy...   \n",
       "\n",
       "                                                text  label  \n",
       "0  Donald Trump s White House is in chaos, and th...      1  \n",
       "1  Now that Donald Trump is the presumptive GOP n...      1  \n",
       "2  Mike Pence is a huge homophobe. He supports ex...      1  \n",
       "3  SAN FRANCISCO (Reuters) - California Attorney ...      0  \n",
       "4  Twisted reasoning is all that comes from Pelos...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "TRUE_PATH = \"True.csv\"  # TODO: set\n",
    "FAKE_PATH = \"Fake.csv\"  # TODO: set\n",
    "\n",
    "true_df = pd.read_csv(TRUE_PATH)[['title','text']].assign(label=0)\n",
    "fake_df = pd.read_csv(FAKE_PATH)[['title','text']].assign(label=1)\n",
    "df = pd.concat([true_df, fake_df], ignore_index=True).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "print(df.shape); df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c0ad6",
   "metadata": {},
   "source": [
    "### 1.2 Class Distribution & Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0198954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counts = df['label'].value_counts().sort_index()\n",
    "print(\"Counts:\", counts.to_dict())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(['Real (0)','Fake (1)'], [counts.get(0,0), counts.get(1,0)])\n",
    "ax.set_title(\"Class Distribution\"); ax.set_ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMissing values:\"); print(df.isna().sum())\n",
    "before = len(df)\n",
    "df = df.dropna(subset=['title','text'])\n",
    "print(f\"Dropped {before - len(df)} rows with nulls in title/text.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0471c7a",
   "metadata": {},
   "source": [
    "### 1.3 Text Preprocessing (tokenize, lowercase, stopwords, lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemm = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = s.lower()\n",
    "    tokens = word_tokenize(s)\n",
    "    kept = []\n",
    "    for t in tokens:\n",
    "        if t.isalpha() and t not in stop_words:\n",
    "            kept.append(lemm.lemmatize(t))\n",
    "    return \" \".join(kept)\n",
    "\n",
    "df['text_clean'] = (df['title'].fillna('') + \" \" + df['text'].fillna('')).apply(clean_text)\n",
    "df[['title','text','text_clean','label']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2907468b",
   "metadata": {},
   "source": [
    "## 2) Feature Engineering (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd49de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,1))\n",
    "X = tfidf.fit_transform(df['text_clean'])\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931901d",
   "metadata": {},
   "source": [
    "## 3) Naive Bayes & Logistic Regression (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b05445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def metrics_report(y_true, y_prob, thresh=0.5, name=\"Model\"):\n",
    "    y_pred = (y_prob >= thresh).astype(int)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    print(f\"{name}: Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} F1={f1:.4f} AUC={auc:.4f}\")\n",
    "    return acc, prec, rec, f1, auc\n",
    "\n",
    "# GaussianNB (requires dense)\n",
    "nb = GaussianNB().fit(X_train.toarray(), y_train)\n",
    "nb_prob = nb.predict_proba(X_test.toarray())[:,1]\n",
    "_ = metrics_report(y_test, nb_prob, name=\"GaussianNB\")\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=100)\n",
    "logreg.fit(X_train, y_train)\n",
    "lr_prob = logreg.predict_proba(X_test)[:,1]\n",
    "_ = metrics_report(y_test, lr_prob, name=\"LogisticRegression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cddb9b4",
   "metadata": {},
   "source": [
    "## 4) Multilayer Perceptron (PyTorch) (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e269c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xtr = torch.from_numpy(X_train.toarray()).float()\n",
    "ytr = torch.from_numpy(y_train.reshape(-1,1)).float()\n",
    "Xte = torch.from_numpy(X_test.toarray()).float()\n",
    "yte = torch.from_numpy(y_test.reshape(-1,1)).float()\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(Xtr, ytr), batch_size=128, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(Xte, yte), batch_size=256, shuffle=False)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "model = MLP(X_train.shape[1])\n",
    "crit = nn.BCELoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def eval_probs(m, loader):\n",
    "    m.eval(); ps=[]; ys=[]\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in loader:\n",
    "            pb = m(xb); ps.append(pb.numpy()); ys.append(yb.numpy())\n",
    "    return np.vstack(ps), np.vstack(ys)\n",
    "\n",
    "EPOCHS = 20\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train(); running=0.0\n",
    "    for xb,yb in train_loader:\n",
    "        opt.zero_grad(); out = model(xb); loss = crit(out, yb)\n",
    "        loss.backward(); opt.step(); running += loss.item()*xb.size(0)\n",
    "    probs, ys = eval_probs(model, test_loader)\n",
    "    try:\n",
    "        auc = roc_auc_score(ys, probs)\n",
    "    except ValueError:\n",
    "        auc = float('nan')\n",
    "    print(f\"Epoch {ep:02d} | loss={running/len(Xtr):.4f} | test AUC={auc:.4f}\")\n",
    "\n",
    "mlp_prob, _ys = eval_probs(model, test_loader)\n",
    "_ = metrics_report(y_test, mlp_prob, name=\"MLP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81723a1b",
   "metadata": {},
   "source": [
    "## 5) Evaluation (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020bafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion(y_true, y_prob, title=\"Confusion Matrix\", threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.set_title(title); ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "def plot_roc_multi(y_true, probs_list, labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    for probs, lbl in zip(probs_list, labels):\n",
    "        fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "        ax.plot(fpr, tpr, label=lbl)\n",
    "    ax.plot([0,1],[0,1],'--')\n",
    "    ax.set_title(\"ROC Curves\"); ax.set_xlabel(\"False Positive Rate\"); ax.set_ylabel(\"True Positive Rate\"); ax.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "plot_confusion(y_test, nb_prob,  \"GaussianNB — Confusion Matrix\")\n",
    "plot_confusion(y_test, lr_prob,  \"Logistic Regression — Confusion Matrix\")\n",
    "plot_confusion(y_test, mlp_prob, \"MLP — Confusion Matrix\")\n",
    "\n",
    "plot_roc_multi(y_test, [nb_prob, lr_prob, mlp_prob], [\"GaussianNB\",\"LogReg\",\"MLP\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672a8ce",
   "metadata": {},
   "source": [
    "## 6) Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39df0c0",
   "metadata": {},
   "source": [
    "\n",
    "- Summarize metrics (Accuracy, Precision, Recall, F1, AUC) for each model.\n",
    "- Discuss false positives vs. false negatives and their implications.\n",
    "- Suggest improvements (bigram features, class weights, threshold tuning, transformer models).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
